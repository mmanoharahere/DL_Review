{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00cab6e9-929f-4b18-9005-d2760cdd5428",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c344a3da-7362-4735-b97e-886772e594e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_step(x_slice, w,b):\n",
    "    s = np.multiply(x_slice,w)\n",
    "    Z = np.sum(s)\n",
    "    Z = Z + float(b)\n",
    "    return Z\n",
    "\n",
    "def conv_forward(X, weight, b, hparams):\n",
    "    \"\"\"\n",
    "    Implements forward pass for a convolution layer\n",
    "\n",
    "    X : input to the current layer (n,H,W,Cin)\n",
    "    W : weights (f, f, Cin, Cout)\n",
    "    b : bias (1, 1, 1, Cout)\n",
    "    hparams : stride, pad\n",
    "\n",
    "    returns:\n",
    "    Z - output (n, Ho, Wo, Cout)\n",
    "    cache - values needed for backward\n",
    "    \"\"\"\n",
    "\n",
    "    # extract params\n",
    "    n,H,W,Cin = X.shape\n",
    "    (f, f, Cin, Cout) = weight.shape\n",
    "    stride = hparams['stride']\n",
    "    pad = hparams['pad']\n",
    "\n",
    "    # compute Ho, Wo\n",
    "    Ho = int((H + 2 * pad - f) /stride) +1\n",
    "    Wo = int((W + 2 * pad - f) /stride) +1\n",
    "    #init output\n",
    "    Z = np.zeros((n, Ho, Wo, Cout))\n",
    "    X_pad = np.pad(X, ((0,0), (pad,pad), (pad,pad), (0,0)), 'constant', constant_values=0)\n",
    "\n",
    "    for i in range(n): #batch\n",
    "        x_curr = X_pad[i] #pick the current input\n",
    "        for h in range(Ho): # height\n",
    "            for w in range(Wo): #width\n",
    "                for c in range(Cout): #channel\n",
    "                    ##slice data\n",
    "                    vert_start = h * stride\n",
    "                    vert_end = vert_start + f\n",
    "                    hor_start = w* stride\n",
    "                    hor_end = hor_start + f\n",
    "                    x_curr_slice = x_curr[vert_start: vert_end, hor_start:hor_end, :]\n",
    "                    Z[i,h,w,c] = conv_step(x_curr_slice, weight[:,:,:,c], b[:,:,:,c])\n",
    "    assert(Z.shape == (n, Ho, Wo, Cout))\n",
    "    cache = (X, weight, b, hparams)\n",
    "\n",
    "    return Z, cache\n",
    "                    \n",
    "\n",
    "#dZ= dL/dO = loss gradient from the previous layer\n",
    "# dL/dF = dL/dO * X\n",
    "# dL/dX = dL/dO * 180 deg rotated F\n",
    "\n",
    "def conv_backward(dZ, cache):\n",
    "\n",
    "    ##extract params\n",
    "    (X, weight, b, hparams) = cache\n",
    "    n,H,W,Cin = X.shape\n",
    "    (f, f, Cin, Cout) = weight.shape\n",
    "    stride = hparams['stride']\n",
    "    pad = hparams['pad']\n",
    "    (n, Ho, Wo, Cout) = dZ.shape\n",
    "\n",
    "    #initialize derivatives\n",
    "\n",
    "    dW = np.zeros((f,f,Cin,Cout))\n",
    "    dX = np.zeros((n,H,W,Cin ))\n",
    "    dB = np.zeros((1,1,1,Cout))\n",
    "\n",
    "    # pad\n",
    "    X_pad = np.pad(X, ((0,0), (pad,pad), (pad,pad), (0,0)), 'constant', constant_values=0)\n",
    "    dX_pad = np.pad(dX, ((0,0), (pad,pad), (pad,pad), (0,0)), 'constant', constant_values=0)\n",
    "\n",
    "\n",
    "    for i in range(n):#batch\n",
    "        x_curr = X_pad[i]\n",
    "        dx_curr = dX_pad[i]\n",
    "\n",
    "        for h in range(Ho):\n",
    "            for w in range(Wo):\n",
    "                for c in range(Cout):\n",
    "                    vert_start = h*stride\n",
    "                    vert_end = vert_start + f\n",
    "                    hor_start = w * stride\n",
    "                    hor_end = hor_start+ f\n",
    "                    \n",
    "                    x_curr_slice = x_curr[vert_start: vert_end, hor_start:hor_end:,:]\n",
    "\n",
    "                    #update gradient\n",
    "                    dx_curr[vert_start: vert_end, hor_start:hor_end:,:]+=weight[:,:,:,c] * dZ[i,h,w,c]\n",
    "                    dW[:,:,:,c] +=x_curr_slice * dZ[i,h,w,c]\n",
    "                    dB[:,:,:,c] += dZ[i,h,w,c]\n",
    "        dX[i,:,:,:] = dx_curr[pad:-pad, pad:-pad,:]\n",
    "\n",
    "    assert(dX.shape == (n, H,W, Cin))\n",
    "\n",
    "    return dX, dW, dB\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85c05be2-6b2a-407d-8f2b-5d72d64a2bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z's mean = 0.048995203528855794\n",
      "Z[3,2,1] = [-0.61490741 -6.7439236  -2.55153897  1.75698377  3.56208902  0.53036437\n",
      "  5.18531798  8.75898442]\n",
      "cache_conv[0][1][2][3] = [-0.20075807  0.18656139  0.41005165]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0z/5t5l4jxx4nb6rh5hnlhb3lsr0000gn/T/ipykernel_13132/1841819400.py:4: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  Z = Z + float(b)\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "A_prev = np.random.randn(10,4,4,3)\n",
    "W = np.random.randn(2,2,3,8)\n",
    "b = np.random.randn(1,1,1,8)\n",
    "hparameters = {\"pad\" : 2,\n",
    "               \"stride\": 2}\n",
    "\n",
    "Z, cache_conv = conv_forward(A_prev, W, b, hparameters)\n",
    "print(\"Z's mean =\", np.mean(Z))\n",
    "print(\"Z[3,2,1] =\", Z[3,2,1])\n",
    "print(\"cache_conv[0][1][2][3] =\", cache_conv[0][1][2][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7211f016-a56e-4072-94ba-a68a59bc3d79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dA_mean = 1.4524377775388075\n",
      "dW_mean = 1.7269914583139097\n",
      "db_mean = 7.839232564616838\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "dA, dW, db = conv_backward(Z, cache_conv)\n",
    "print(\"dA_mean =\", np.mean(dA))\n",
    "print(\"dW_mean =\", np.mean(dW))\n",
    "print(\"db_mean =\", np.mean(db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa6d4a9-abca-4b9e-8087-34a60cc1ce59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
